{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras-based Machine Learning Pipeline\n",
    "\n",
    "This is a pipeline for doing data analsis using the Keras package and Tensorflow.\n",
    "\n",
    "**Steps:**\n",
    "1. Load SITL reports\n",
    "2. Load MMS data\n",
    "3. Data preprocessing\n",
    "4. Train LSTM model\n",
    "\n",
    "Introduction to LSTMs and Keras: https://adventuresinmachinelearning.com/keras-lstm-tutorial/\n",
    "\n",
    "Can base this on an example from Machine Learning Mastery: https://machinelearningmastery.com/how-to-develop-rnn-models-for-human-activity-recognition-time-series-classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.dates import num2date, date2num\n",
    "import random\n",
    "\n",
    "# Machine learning\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import retrieve_sitl\n",
    "import retrieve_mms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load SITL data\n",
    "\n",
    "Load parsed reports in. Following would be useful:\n",
    "- Reports reduced to \"BBF\" / \"DF\" / some other interesting signals\n",
    "- Starttime and endtime and duration provided\n",
    "- If the report was for multiple events or single event or not\n",
    "- FOM value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FOM</th>\n",
       "      <th>ID</th>\n",
       "      <th>Discussion</th>\n",
       "      <th>Starttime</th>\n",
       "      <th>Endtime</th>\n",
       "      <th>Day</th>\n",
       "      <th>FOM_float</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Discussion_contains_BBF</th>\n",
       "      <th>Discussion_contains_DF</th>\n",
       "      <th>Discussion_contains_uncertainty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>25.0</td>\n",
       "      <td>icohen(EVA)</td>\n",
       "      <td>Dipolarization features, particle boundary an...</td>\n",
       "      <td>2016-04-13 00:37:54</td>\n",
       "      <td>2016-04-13 01:04:54</td>\n",
       "      <td>2016-04-13</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0 days 00:27:00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>40.0</td>\n",
       "      <td>jburch(EVA)</td>\n",
       "      <td>Possible dipolarization front</td>\n",
       "      <td>2016-04-24 12:13:14</td>\n",
       "      <td>2016-04-24 16:18:24</td>\n",
       "      <td>2016-04-24</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0 days 04:05:10</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>20.0</td>\n",
       "      <td>jburch(EVA)</td>\n",
       "      <td>Possible dipolarization front</td>\n",
       "      <td>2016-04-26 10:22:34</td>\n",
       "      <td>2016-04-26 10:26:34</td>\n",
       "      <td>2016-04-26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0 days 00:04:00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>40.0</td>\n",
       "      <td>jburch(EVA)</td>\n",
       "      <td>Possible dipolarization event</td>\n",
       "      <td>2016-04-27 15:14:34</td>\n",
       "      <td>2016-04-27 15:45:04</td>\n",
       "      <td>2016-04-27</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0 days 00:30:30</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>40.0</td>\n",
       "      <td>jburch(EVA)</td>\n",
       "      <td>Possible dipolarization front, 400 km/s Sunwa...</td>\n",
       "      <td>2016-04-29 10:18:24</td>\n",
       "      <td>2016-04-29 10:23:14</td>\n",
       "      <td>2016-04-29</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0 days 00:04:50</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482</th>\n",
       "      <td>10.0</td>\n",
       "      <td>ocontel(EVA)</td>\n",
       "      <td>Small dipolarization with dawnward flow (Vy=...</td>\n",
       "      <td>2016-09-11 20:44:04</td>\n",
       "      <td>2016-09-11 20:50:14</td>\n",
       "      <td>2016-09-11</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0 days 00:06:10</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>20.0</td>\n",
       "      <td>ocontel(EVA)</td>\n",
       "      <td>DF with Vy=-300 km/s</td>\n",
       "      <td>2016-09-11 22:03:04</td>\n",
       "      <td>2016-09-11 22:08:54</td>\n",
       "      <td>2016-09-11</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0 days 00:05:50</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>10.0</td>\n",
       "      <td>ocontel(EVA)</td>\n",
       "      <td>Dawnward flow Vy=-150 km/s (DF like) with LF...</td>\n",
       "      <td>2016-09-16 20:20:44</td>\n",
       "      <td>2016-09-16 20:27:24</td>\n",
       "      <td>2016-09-16</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0 days 00:06:40</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1655</th>\n",
       "      <td>15.0</td>\n",
       "      <td>hhiroshi(EVA)</td>\n",
       "      <td>weak earthward &amp; dawnward flow with possible ...</td>\n",
       "      <td>2016-09-20 00:56:04</td>\n",
       "      <td>2016-09-20 01:05:34</td>\n",
       "      <td>2016-09-20</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0 days 00:09:30</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1665</th>\n",
       "      <td>20.0</td>\n",
       "      <td>hhiroshi(EVA)</td>\n",
       "      <td>possible dipolarization with northward flow a...</td>\n",
       "      <td>2016-09-21 00:20:24</td>\n",
       "      <td>2016-09-21 00:25:04</td>\n",
       "      <td>2016-09-21</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0 days 00:04:40</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>350 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         FOM              ID  \\\n",
       "124     25.0     icohen(EVA)   \n",
       "298     40.0     jburch(EVA)   \n",
       "312     20.0     jburch(EVA)   \n",
       "327     40.0     jburch(EVA)   \n",
       "341     40.0     jburch(EVA)   \n",
       "...      ...             ...   \n",
       "1482    10.0    ocontel(EVA)   \n",
       "1487    20.0    ocontel(EVA)   \n",
       "1596    10.0    ocontel(EVA)   \n",
       "1655    15.0   hhiroshi(EVA)   \n",
       "1665    20.0   hhiroshi(EVA)   \n",
       "\n",
       "                                             Discussion           Starttime  \\\n",
       "124    Dipolarization features, particle boundary an... 2016-04-13 00:37:54   \n",
       "298                      Possible dipolarization front  2016-04-24 12:13:14   \n",
       "312                      Possible dipolarization front  2016-04-26 10:22:34   \n",
       "327                      Possible dipolarization event  2016-04-27 15:14:34   \n",
       "341    Possible dipolarization front, 400 km/s Sunwa... 2016-04-29 10:18:24   \n",
       "...                                                 ...                 ...   \n",
       "1482    Small dipolarization with dawnward flow (Vy=... 2016-09-11 20:44:04   \n",
       "1487                               DF with Vy=-300 km/s 2016-09-11 22:03:04   \n",
       "1596    Dawnward flow Vy=-150 km/s (DF like) with LF... 2016-09-16 20:20:44   \n",
       "1655   weak earthward & dawnward flow with possible ... 2016-09-20 00:56:04   \n",
       "1665   possible dipolarization with northward flow a... 2016-09-21 00:20:24   \n",
       "\n",
       "                 Endtime         Day  FOM_float        Duration  \\\n",
       "124  2016-04-13 01:04:54  2016-04-13       25.0 0 days 00:27:00   \n",
       "298  2016-04-24 16:18:24  2016-04-24       40.0 0 days 04:05:10   \n",
       "312  2016-04-26 10:26:34  2016-04-26       20.0 0 days 00:04:00   \n",
       "327  2016-04-27 15:45:04  2016-04-27       40.0 0 days 00:30:30   \n",
       "341  2016-04-29 10:23:14  2016-04-29       40.0 0 days 00:04:50   \n",
       "...                  ...         ...        ...             ...   \n",
       "1482 2016-09-11 20:50:14  2016-09-11       10.0 0 days 00:06:10   \n",
       "1487 2016-09-11 22:08:54  2016-09-11       20.0 0 days 00:05:50   \n",
       "1596 2016-09-16 20:27:24  2016-09-16       10.0 0 days 00:06:40   \n",
       "1655 2016-09-20 01:05:34  2016-09-20       15.0 0 days 00:09:30   \n",
       "1665 2016-09-21 00:25:04  2016-09-21       20.0 0 days 00:04:40   \n",
       "\n",
       "      Discussion_contains_BBF  Discussion_contains_DF  \\\n",
       "124                     False                    True   \n",
       "298                     False                    True   \n",
       "312                     False                    True   \n",
       "327                     False                    True   \n",
       "341                     False                    True   \n",
       "...                       ...                     ...   \n",
       "1482                    False                    True   \n",
       "1487                    False                    True   \n",
       "1596                    False                    True   \n",
       "1655                    False                    True   \n",
       "1665                    False                    True   \n",
       "\n",
       "      Discussion_contains_uncertainty  \n",
       "124                             False  \n",
       "298                             False  \n",
       "312                             False  \n",
       "327                             False  \n",
       "341                             False  \n",
       "...                               ...  \n",
       "1482                            False  \n",
       "1487                            False  \n",
       "1596                            False  \n",
       "1655                             True  \n",
       "1665                             True  \n",
       "\n",
       "[350 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the reports in 2016 with DFs:\n",
    "pickle_path = \"../pydata/DF_2016_reports_parsed_df.p\"   # pickle created in example_sitl_read.ipynb\n",
    "reports_df_2016 = pd.read_pickle(pickle_path)\n",
    "reports_df_2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FOM</th>\n",
       "      <th>ID</th>\n",
       "      <th>Discussion</th>\n",
       "      <th>Starttime</th>\n",
       "      <th>Endtime</th>\n",
       "      <th>Day</th>\n",
       "      <th>FOM_float</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Discussion_contains_BBF</th>\n",
       "      <th>Discussion_contains_DF</th>\n",
       "      <th>Discussion_contains_uncertainty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>10.0</td>\n",
       "      <td>ocontel(EVA)</td>\n",
       "      <td>Small dipolarization, low frequency E waves ...</td>\n",
       "      <td>2016-09-11 18:35:24</td>\n",
       "      <td>2016-09-11 18:40:04</td>\n",
       "      <td>2016-09-11</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0 days 00:04:40</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1481</th>\n",
       "      <td>10.0</td>\n",
       "      <td>ocontel(EVA)</td>\n",
       "      <td>Small dipolarization with low frequency E wa...</td>\n",
       "      <td>2016-09-11 20:36:24</td>\n",
       "      <td>2016-09-11 20:42:14</td>\n",
       "      <td>2016-09-11</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0 days 00:05:50</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482</th>\n",
       "      <td>10.0</td>\n",
       "      <td>ocontel(EVA)</td>\n",
       "      <td>Small dipolarization with dawnward flow (Vy=...</td>\n",
       "      <td>2016-09-11 20:44:04</td>\n",
       "      <td>2016-09-11 20:50:14</td>\n",
       "      <td>2016-09-11</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0 days 00:06:10</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>20.0</td>\n",
       "      <td>ocontel(EVA)</td>\n",
       "      <td>DF with Vy=-300 km/s</td>\n",
       "      <td>2016-09-11 22:03:04</td>\n",
       "      <td>2016-09-11 22:08:54</td>\n",
       "      <td>2016-09-11</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0 days 00:05:50</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        FOM             ID                                         Discussion  \\\n",
       "1479   10.0   ocontel(EVA)    Small dipolarization, low frequency E waves ...   \n",
       "1481   10.0   ocontel(EVA)    Small dipolarization with low frequency E wa...   \n",
       "1482   10.0   ocontel(EVA)    Small dipolarization with dawnward flow (Vy=...   \n",
       "1487   20.0   ocontel(EVA)                               DF with Vy=-300 km/s   \n",
       "\n",
       "               Starttime             Endtime         Day  FOM_float  \\\n",
       "1479 2016-09-11 18:35:24 2016-09-11 18:40:04  2016-09-11       10.0   \n",
       "1481 2016-09-11 20:36:24 2016-09-11 20:42:14  2016-09-11       10.0   \n",
       "1482 2016-09-11 20:44:04 2016-09-11 20:50:14  2016-09-11       10.0   \n",
       "1487 2016-09-11 22:03:04 2016-09-11 22:08:54  2016-09-11       20.0   \n",
       "\n",
       "            Duration  Discussion_contains_BBF  Discussion_contains_DF  \\\n",
       "1479 0 days 00:04:40                    False                    True   \n",
       "1481 0 days 00:05:50                    False                    True   \n",
       "1482 0 days 00:06:10                    False                    True   \n",
       "1487 0 days 00:05:50                    False                    True   \n",
       "\n",
       "      Discussion_contains_uncertainty  \n",
       "1479                            False  \n",
       "1481                            False  \n",
       "1482                            False  \n",
       "1487                            False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here's an example event, but ideally we would have a list of these events:\n",
    "#events = reports_df_2016   # correct version\n",
    "events = reports_df_2016[reports_df_2016.Day.str.contains('2016-09-11')]\n",
    "# --------------------------------------------------------------\n",
    "# USE ALL EVENTS WHEN ALL DATA AVAILABLE! I only used one example day.\n",
    "# --------------------------------------------------------------\n",
    "events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load MMS data\n",
    "\n",
    "Load in raw data for processing.\n",
    "\n",
    "Load both magnetic (FGM) and plasma/ion data (FPI, not yet implemented). Both will be useful to feed into a machine learning algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file at ../pydata/mms1/fgm/srvy/l2/2016/09/mms1_fgm_srvy_l2_20160911_v5.87.0.cdf\n"
     ]
    }
   ],
   "source": [
    "# Read FGM data:\n",
    "# ---------------------------------------\n",
    "#starttime, endtime = datetime(2016,6,1), datetime(2017,1,1)   # these dates should be for the available data\n",
    "# ---------------------------------------\n",
    "starttime, endtime = datetime(2016,9,11), datetime(2016,9,12)\n",
    "local_data_dir = '../pydata'\n",
    "base_path = os.path.join(local_data_dir, 'mms1', 'fgm', 'srvy', 'l2')\n",
    "data = retrieve_mms.get_fgm(base_path, starttime, endtime)\n",
    "t_utc, B_x, B_y, B_z, Bt = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also read FPI data:\n",
    "base_path = os.path.join(local_data_dir, 'mms1', 'fpi', 'fast', 'l2', 'dis-moms')\n",
    "data = retrieve_mms.get_fpi(base_path, starttime, endtime)\n",
    "t_utc_fpi, speed_x, speed_y, speed_z, density = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data proprocessing\n",
    "\n",
    "First steps...\n",
    "\n",
    "1. Resample data to 1s? I don't think we need a higher resolution. Maybe somebody else knows better here.\n",
    "2. Label data with classes, e.g. all data has class 0 to start with, data marked as BBF in reports is then labelled with class 1, then data marked as DF is labelled with class 2, etc. We can try to predict the event type contained in a short time series within the data.\n",
    "3. May want to remove general trends so data is static. I think the signals we're looking for are only related to variations, not to overall increase/decrease in magnetic field values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample data:\n",
    "# --------------\n",
    "# (Iterating over datetime takes a while - this could be optimised)\n",
    "t_sec = np.array([starttime + timedelta(seconds=n) for n in range(int((endtime-starttime).total_seconds()))])\n",
    "t_sec_num = date2num(t_sec)\n",
    "t_utc_num = date2num(t_utc)\n",
    "# Interpolate to new time array:\n",
    "B_x_sec = np.interp(t_sec_num, t_utc_num, B_x)\n",
    "B_y_sec = np.interp(t_sec_num, t_utc_num, B_y)\n",
    "B_z_sec = np.interp(t_sec_num, t_utc_num, B_z)\n",
    "Bt_sec = np.interp(t_sec_num, t_utc_num, Bt)\n",
    "# --------------------------------------------------------------\n",
    "# Could add in gradient here! Detrending would be more complicated because each slice (below) would have to be detrended\n",
    "# --------------------------------------------------------------\n",
    "# FPI data:     # uncomment this when FPI data is available!\n",
    "#t_utc_fpi_num = date2num(t_utc_fpi)\n",
    "#speedx_sec = np.interp(t_sec_num, t_utc_fpi_num, speed_x)   # can also try with y and z\n",
    "#density_sec = np.interp(t_sec_num, t_utc_fpi_num, density)\n",
    "\n",
    "# Combine all features (input data) into array:\n",
    "all_features = np.hstack(( B_x_sec.reshape(-1,1), \n",
    "                           B_y_sec.reshape(-1,1), \n",
    "                           B_z_sec.reshape(-1,1),\n",
    "                           Bt_sec.reshape(-1,1)),\n",
    "                           #speedx_sec.reshape(-1,1),\n",
    "                           #density_sec.reshape(-1,1)     # uncomment this when FPI data is available!\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values in array: [0. 1.]\n",
      "DFs: 1.6 % of data set\n"
     ]
    }
   ],
   "source": [
    "# Create arrays with data classes:\n",
    "# --------------------------------\n",
    "# 1 is the label in the data for \"contains DF\"!\n",
    "t_classes = np.zeros(len(t_sec))\n",
    "for index, event in events.iterrows():\n",
    "    t_classes[np.logical_and(t_sec >= event.Starttime, t_sec < event.Endtime)] = 1\n",
    "print(\"Values in array:\", np.unique(t_classes))\n",
    "print(\"DFs: {:.1f} % of data set\".format(np.count_nonzero(t_classes)/len(t_classes)*100.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps in preparation for machine learning\n",
    "\n",
    "Combine all MMC variables into one array, and then...\n",
    "\n",
    "1. Split MMS data into 30-minute time slices (samples).\n",
    "2. Give each section a class if it contains an interesting signal. Use keras.utils.to_categorical() on this.\n",
    "3. Scale input data for LSTM (sklearn.MixMaxScaler).\n",
    "4. Make a train-test split of all data.\n",
    "5. Input data (X) should be n-dimensional and contain magnetic field variations and ion data. **What else can we add to this?** Output data (y) should be 2-dimensional and contain one class (int value, 0 or 1) per time slice. It's a good place to start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing variables\n",
    "# ----------------------------\n",
    "# Minutes in slice determines the size of the samples given to the net:\n",
    "mins_in_slice = 5 # 30\n",
    "# Batch size determines the number of samples given to the net for one iteration:\n",
    "batch_size = 4 # try to keep this as a power of 2\n",
    "# Epochs is the number of times the neural net / LSTM iterates to find the best. \n",
    "# A higher number usually means more accurate, but put it too high and you overtrain.\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples:\t\t 16\n",
      "Number of timesteps:\t\t 300\n",
      "Number of features in X:\t 4\n",
      "Number of categories in y:\t 2\n",
      "Shape of X = (16, 300, 4), y = (16, 2)\n"
     ]
    }
   ],
   "source": [
    "# Define X - the model input\n",
    "# --------------------------\n",
    "# Scale data to the range (0,1), NN won't be happy with unscaled data\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_X.fit(all_features)\n",
    "all_features_scaled = scaler_X.transform(all_features)\n",
    "# X contains the magnetic field measurements and (soon) the plasma instrument data\n",
    "all_features_split = np.array_split(all_features_scaled, 86400/(60*mins_in_slice))\n",
    "X_all = np.array(all_features_split)\n",
    "\n",
    "# Define y - the desired output\n",
    "# -----------------------------\n",
    "# In this case y is binary: 0 (= no DF) or 1 (= contains DF)\n",
    "t_classes_split = np.array_split(t_classes, 86400/(60*mins_in_slice))\n",
    "y_all = np.array([int(max(x)) for x in t_classes_split]).reshape(-1,1)\n",
    "\n",
    "# Reduce samples so that number of samples with/without DFs are balanced\n",
    "# ----------------------------------------------------------------------\n",
    "# Find where DFs are:\n",
    "DF_slices = np.where(y_all==1)[0]\n",
    "all_slices = [x for x in list(range(len(y_all))) if x not in DF_slices]\n",
    "# Find where DFs aren't and get equal number of samples:\n",
    "noDF_slices = random.sample(all_slices, len(DF_slices))\n",
    "X_DFs = X_all[DF_slices]\n",
    "X_noDFs = X_all[noDF_slices]\n",
    "X = np.vstack((X_DFs, X_noDFs))\n",
    "y_DFs = y_all[DF_slices]\n",
    "y_noDFs = y_all[noDF_slices]\n",
    "y = np.vstack((y_DFs, y_noDFs))\n",
    "\n",
    "# Make y into categorical:\n",
    "y = to_categorical(y)\n",
    "\n",
    "# Output sizes:\n",
    "print(\"Number of samples:\\t\\t\", X.shape[0])\n",
    "print(\"Number of timesteps:\\t\\t\", X.shape[1])\n",
    "print(\"Number of features in X:\\t\", X.shape[2])\n",
    "print(\"Number of categories in y:\\t\", y.shape[1])\n",
    "print(\"Shape of X = {}, y = {}\".format(X.shape, y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train LSTM model\n",
    "\n",
    "Take this as starting example: https://machinelearningmastery.com/how-to-develop-rnn-models-for-human-activity-recognition-time-series-classification/\n",
    "\n",
    "Ideas on how to improve the accuracy:\n",
    "- Change the LSTM format. Remove the dropout, change it, add a special metric, etc.\n",
    "- Use more epochs. Find a cut-off point before it starts overtraining (which is when the training accuracy is much higher than the testing accuracy, which shouldn't happen).\n",
    "- Change the batch_size.\n",
    "- Change up the mins_in_slice variable. Is it better with shorter or longer time slices? It may be better with longer time slices because some reports include DFs with comments on other signals, leading to some time slices being labelled as DFs but having no relevant signal. These will contaminate the dataset.\n",
    "- Add other features into the input array X, e.g. detrended data, maybe a derivative, or combinations of different variables.\n",
    "- Remove some features - too many can also bad.\n",
    "- Only use data with higher FOM values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define basic machine learning model:\n",
    "def evaluate_model(trainX, trainy, testX, testy, epochs=15, batch_size=64):\n",
    "    verbose = 0\n",
    "    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, input_shape=(n_timesteps,n_features)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # fit network\n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    # evaluate model\n",
    "    _, train_accuracy = model.evaluate(trainX, trainy, batch_size=batch_size, verbose=0)\n",
    "    _, test_accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "    return train_accuracy, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58.3% correct in training\n",
      "25.0% correct in testing\n"
     ]
    }
   ],
   "source": [
    "score_train, score_test = evaluate_model(X_train, y_train, X_test, y_test, batch_size=batch_size, epochs=epochs)\n",
    "print(\"{:.1f}% correct in training\".format(score_train*100.))\n",
    "print(\"{:.1f}% correct in testing\".format(score_test*100.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Apply trained model to new times\n",
    "\n",
    "Once model is trained, can we use it to find similar signals in data outside what we've trained it on? Would be cool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# would be nice..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
